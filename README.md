# Neighborhood Traffic Monitoring System

A hybrid edge-cloud architecture for monitoring and analyzing traffic patterns on residential streets using a Raspberry Pi (or similar device) and optional Google Cloud Platform sync for data processing.

## Problem Statement

Residential streets often lack objective data about traffic patterns, volumes, and speeds. This project provides a complete monitoring system to collect and analyze traffic data for advocacy, planning, and traffic calming initiatives. The system produces credible, evidence-grade data suitable for presentations to municipal authorities and community stakeholders.

## Architecture Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         TRAFFIC MONITOR                                ‚îÇ
‚îÇ                  Evidence-Grade Traffic Data Collection                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  OBSERVATION LAYER (src/observation/)                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îÇ
‚îÇ  ‚îÇ OpenCVSource ‚îÇ  ‚îÇPicamera2Src  ‚îÇ  ‚îÇ   VideoFile  ‚îÇ                 ‚îÇ
‚îÇ  ‚îÇ  (USB/RTSP)  ‚îÇ  ‚îÇ   (Pi CSI)   ‚îÇ  ‚îÇ   (Testing)  ‚îÇ                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                 ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                        ‚îÇ
‚îÇ                      ‚Üì FrameData (BGR, timestamp, transforms)          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PIPELINE ENGINE (src/pipeline/)                                       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ  ‚îÇ  Detect  ‚îÇ‚Üí ‚îÇ  Track   ‚îÇ‚Üí ‚îÇ Measure  ‚îÇ‚Üí ‚îÇ Persist  ‚îÇ              ‚îÇ
‚îÇ  ‚îÇ  Stage   ‚îÇ  ‚îÇ  Stage   ‚îÇ  ‚îÇ  Stage   ‚îÇ  ‚îÇ  Stage   ‚îÇ              ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì             ‚Üì             ‚Üì             ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   DETECTION    ‚îÇ ‚îÇ TRACKING ‚îÇ ‚îÇ  COUNTING   ‚îÇ ‚îÇ      STORAGE         ‚îÇ
‚îÇ (src/detection)‚îÇ ‚îÇ(src/track‚îÇ ‚îÇ(src/algos)  ‚îÇ ‚îÇ   (src/storage)      ‚îÇ
‚îÇ                ‚îÇ ‚îÇ   ing)   ‚îÇ ‚îÇ             ‚îÇ ‚îÇ                      ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ          ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ ‚îÇ   BgSub    ‚îÇ ‚îÇ ‚îÇ   IoU    ‚îÇ ‚îÇ ‚îÇ  Gate   ‚îÇ ‚îÇ ‚îÇ  ‚îÇ  count_events  ‚îÇ ‚îÇ
‚îÇ ‚îÇ  Detector  ‚îÇ ‚îÇ ‚îÇ  Tracker ‚îÇ ‚îÇ ‚îÇ Counter ‚îÇ ‚îÇ ‚îÇ  ‚îÇ   (schema v3)  ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ          ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§ ‚îÇ ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îÇ                ‚îÇ ‚îÇ  Track   ‚îÇ ‚îÇ ‚îÇ  Line   ‚îÇ ‚îÇ ‚îÇ  ‚îÇ ‚Ä¢ class_id     ‚îÇ ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇ   with   ‚îÇ ‚îÇ ‚îÇ Counter ‚îÇ ‚îÇ ‚îÇ  ‚îÇ ‚Ä¢ confidence   ‚îÇ ‚îÇ
‚îÇ ‚îÇ   YOLO     ‚îÇ ‚îÇ ‚îÇ metadata ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ  ‚îÇ ‚Ä¢ backend      ‚îÇ ‚îÇ
‚îÇ ‚îÇ (GPU/CPU)  ‚îÇ ‚îÇ ‚îÇ          ‚îÇ ‚îÇ             ‚îÇ ‚îÇ  ‚îÇ ‚Ä¢ direction    ‚îÇ ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ ‚îÇ  Double  ‚îÇ ‚îÇ  Canonical  ‚îÇ ‚îÇ  ‚îÇ ‚Ä¢ timestamp    ‚îÇ ‚îÇ
‚îÇ        ‚Üì       ‚îÇ ‚îÇ  count   ‚îÇ ‚îÇ  direction  ‚îÇ ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ ‚îÇprevention‚îÇ ‚îÇ    codes    ‚îÇ ‚îÇ           ‚Üì         ‚îÇ
‚îÇ ‚îÇ   Hailo    ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ  (A_TO_B,   ‚îÇ ‚îÇ  Unique constraint  ‚îÇ
‚îÇ ‚îÇ   (NPU)    ‚îÇ ‚îÇ              ‚îÇ   B_TO_A)   ‚îÇ ‚îÇ  Defense-in-depth   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                        ‚îÇ
         ‚Üì                                                ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                 ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  INFERENCE BACKENDS        ‚îÇ                 ‚îÇ   CLOUD SYNC         ‚îÇ
‚îÇ  (src/inference)           ‚îÇ                 ‚îÇ   (src/cloud)        ‚îÇ
‚îÇ                            ‚îÇ                 ‚îÇ                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ                 ‚îÇ  ‚Ä¢ BigQuery upload   ‚îÇ
‚îÇ  ‚îÇ  CPU Backend         ‚îÇ  ‚îÇ                 ‚îÇ  ‚Ä¢ Cloud Storage     ‚îÇ
‚îÇ  ‚îÇ  (Ultralytics YOLO)  ‚îÇ  ‚îÇ                 ‚îÇ  ‚Ä¢ Async/optional    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ                 ‚îÇ  ‚Ä¢ Schema v3         ‚îÇ
‚îÇ                            ‚îÇ                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  Hailo Backend       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (HailoRT NPU)       ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WEB LAYER (src/web + frontend/)                                       ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  FastAPI Backend              React Frontend (TypeScript + Tailwind)   ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ API Routes          ‚îÇ      ‚îÇ ‚Ä¢ Dashboard (live video + counts)   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ /api/status       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Configure (gate lines, settings)  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ /api/stats/*      ‚îÇ      ‚îÇ ‚Ä¢ Health (system metrics)           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ /api/config       ‚îÇ      ‚îÇ ‚Ä¢ Trends (time-series charts)       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ /api/calibration  ‚îÇ      ‚îÇ ‚Ä¢ Logs (system log viewer)          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ /api/camera/live  ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                               ‚îÇ
‚îÇ                                                                         ‚îÇ
‚îÇ  Services Layer (src/web/services/)                                    ‚îÇ
‚îÇ  ‚Ä¢ Stats service (modal split, time-series)                            ‚îÇ
‚îÇ  ‚Ä¢ Config service (3-layer merge: default ‚Üí config ‚Üí calibration)      ‚îÇ
‚îÇ  ‚Ä¢ Status service (compact polling, health metrics)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  RUNTIME CONTEXT (src/runtime/)                                        ‚îÇ
‚îÇ  ‚Ä¢ Platform metadata capture                                           ‚îÇ
‚îÇ  ‚Ä¢ Service initialization and dependency injection                     ‚îÇ
‚îÇ  ‚Ä¢ Configuration management (3-layer architecture)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

KEY ARCHITECTURAL PRINCIPLES:
‚úì Observation ‚Üí Detection ‚Üí Tracking ‚Üí Counting ‚Üí Storage (strict layers)
‚úì Pluggable backends at each layer (camera, detection, inference)
‚úì Edge-first: runs without internet, cloud sync is optional
‚úì Defense-in-depth: double-count prevention (track state + DB constraint)
‚úì Schema v3: comprehensive metadata for evidence-grade analysis
```

### Key Components

1. **Observation Layer** (`src/observation/`)
   - Abstracts frame sources (USB cameras, RTSP, Pi CSI, video files)
   - Returns `FrameData` objects with timestamps
   - Handles reconnection and transforms (rotate, flip, swap_rb)

2. **Pipeline Engine** (`src/pipeline/`)
   - Clear stages: Preprocess ‚Üí Detect ‚Üí Track ‚Üí Measure ‚Üí Persist
   - Tracking produces trajectories for counting analysis
   - MeasureStage applies selected counting strategy

3. **Detection Backends** (`src/detection/`)
   - **Background Subtraction**: CPU-only, single-class detection
   - **YOLO (GPU/CPU)**: Multi-class object detection (person, bicycle, car, motorcycle, bus, truck)
   - **Hailo (NPU)**: Hardware-accelerated YOLO for Raspberry Pi 5 (planned)
   - All backends preserve class metadata through the pipeline

4. **Counting Strategies** (`src/algorithms/counting/`)
   - **GateCounter** (default): Two-line gate for bi-directional streets
   - **LineCounter**: Single-line fallback
   - All strategies emit canonical `CountEvent` with direction codes and class metadata
   - Defense-in-depth: prevents double-counting via track state + database constraints

5. **Storage** (`src/storage/`)
   - Single canonical table: `count_events` (schema v3)
   - Stores class metadata (class_id, class_name, confidence, detection_backend)
   - Stats derived exclusively from `count_events`
   - Unique constraint prevents duplicate counts

6. **Web API** (`src/web/`)
   - JSON APIs for frontend (`/api/status`, `/api/stats/*`)
   - Modal split statistics: `/api/stats/by-class`
   - MJPEG streaming at `/api/camera/live.mjpg`
   - Configuration management

7. **Frontend** (`frontend/`)
   - React + TypeScript + Tailwind + shadcn/ui
   - **Dashboard**: Live video feed + real-time counts + system status
   - **Configure**: Gate lines, camera settings, detection parameters
   - **Health**: System metrics, storage, temperature, uptime
   - **Trends**: Time-series analysis, historical patterns
   - **Logs**: System log viewer with filtering

## Project Structure

```
traffic-monitor/
‚îú‚îÄ‚îÄ config/                     # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ default.yaml           # Defaults (do not edit)
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml            # Local overrides
‚îÇ   ‚îî‚îÄ‚îÄ cloud_config.yaml      # GCP settings
‚îÇ
‚îú‚îÄ‚îÄ src/                        # Backend source
‚îÇ   ‚îú‚îÄ‚îÄ main.py                # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ observation/           # Frame sources (OpenCV, Picamera2)
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/              # Processing engine + stages
‚îÇ   ‚îú‚îÄ‚îÄ algorithms/counting/   # Counting strategies (Gate, Line)
‚îÇ   ‚îú‚îÄ‚îÄ detection/             # Detection (BgSub detector)
‚îÇ   ‚îú‚îÄ‚îÄ inference/             # AI backends (YOLO/GPU, Hailo/NPU)
‚îÇ   ‚îú‚îÄ‚îÄ tracking/              # Object tracking
‚îÇ   ‚îú‚îÄ‚îÄ storage/               # SQLite database
‚îÇ   ‚îú‚îÄ‚îÄ models/                # Data models (FrameData, CountEvent, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ runtime/               # Runtime context + services
‚îÇ   ‚îú‚îÄ‚îÄ web/                   # FastAPI + Jinja2 (legacy)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/            # API routes
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/          # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ cloud/                 # GCP sync
‚îÇ   ‚îî‚îÄ‚îÄ ops/                   # Logging, health, process management
‚îÇ
‚îú‚îÄ‚îÄ frontend/                   # React frontend
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/             # Dashboard, Configure, Health, Trends, Logs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/        # UI components
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ lib/               # API client, utilities
‚îÇ   ‚îî‚îÄ‚îÄ dist/                  # Built frontend (served by FastAPI)
‚îÇ
‚îú‚îÄ‚îÄ secrets/                    # Credentials (gitignored)
‚îÇ   ‚îú‚îÄ‚îÄ gcp-credentials.json
‚îÇ   ‚îî‚îÄ‚îÄ camera_secrets.yaml
‚îÇ
‚îú‚îÄ‚îÄ tests/                      # Unit tests
‚îú‚îÄ‚îÄ docs/                       # Documentation
‚îî‚îÄ‚îÄ tools/                      # Deployment scripts
```

## Quick Start

### 1. Install Dependencies

```bash
git clone https://github.com/your-username/traffic-monitor.git
cd traffic-monitor

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\Scripts\activate   # Windows

# Install Python dependencies
pip install -r requirements.txt

# Build frontend
cd frontend
npm install
npm run build
cd ..
```

### 2. Configure

Copy and edit the config:

```bash
cp config/default.yaml config/config.yaml
```

**For USB camera:**
```yaml
camera:
  backend: "opencv"
  device_id: 0
  resolution: [1280, 720]
  fps: 30

counting:
  mode: "gate"  # Two-line gate counting (default)
  line_a: [[0.2, 1.0], [0.0, 0.0]]
  line_b: [[0.8, 1.0], [1.0, 0.0]]
  direction_labels:
    a_to_b: "northbound"
    b_to_a: "southbound"
```

**For Pi Camera:**
```yaml
camera:
  backend: "picamera2"
  resolution: [1280, 720]
  fps: 30
```

**For RTSP camera:**
```yaml
camera:
  backend: "opencv"
  device_id: "rtsp://192.168.1.100/stream"
  secrets_file: "secrets/camera_secrets.yaml"
```

### 3. Run

```bash
python src/main.py --config config/config.yaml
```

Access the web interface at: `http://localhost:5000`

### Options

- `--display`: Show OpenCV window (for debugging)
- `--record`: Record video to `output/video/`
- `--stop`: Stop any running instance and exit
- `--kill-existing`: Kill existing instance before starting (ensures single instance)

### Process Management

The system enforces single-instance operation via PID file (`data/traffic_monitor.pid`):

```bash
# Stop a running instance
python src/main.py --stop

# Replace existing instance
python src/main.py --config config/config.yaml --kill-existing
```

## Counting Strategies

### Gate Counting (Default)

Two-line gate counting is the standard for bi-directional streets:

```
        Line A          Line B
          ‚îÇ               ‚îÇ
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          ‚îÇ    STREET     ‚îÇ
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
          ‚îÇ               ‚îÇ

Vehicle crossing A ‚Üí B = "A_TO_B" (northbound)
Vehicle crossing B ‚Üí A = "B_TO_A" (southbound)
```

Configure in `config.yaml`:
```yaml
counting:
  mode: "gate"
  line_a: [[0.2, 1.0], [0.0, 0.0]]  # Ratios [0-1]
  line_b: [[0.8, 1.0], [1.0, 0.0]]
  max_gap_frames: 30  # Max frames between A/B crossings
```

### Line Counting (Fallback)

Single-line counting for simple scenarios:

```yaml
counting:
  mode: "line"
  line_a: [[0.5, 1.0], [0.5, 0.0]]  # Vertical center line
```

## Detection Backends

The system supports multiple detection backends, configurable for different hardware:

| Backend | Hardware | Classification | Classes Detected | Use Case |
|---------|----------|----------------|------------------|----------|
| `bgsub` | Any CPU | ‚ùå Single-class | Motion blobs (unclassified) | Default, no dependencies, works everywhere |
| `yolo` | GPU (CUDA) or CPU | ‚úÖ Multi-class | person, bicycle, car, motorcycle, bus, truck | Best for desktop/dev, enables modal split |
| `hailo` | Hailo NPU (Pi 5) | ‚úÖ Multi-class | person, bicycle, car, motorcycle, bus, truck | Best for edge deployment (üìã PLANNED - placeholder stub exists, implementation pending) |

**Classification Details:**
- **Multi-class backends** (`yolo`, `hailo`) enable modal split analysis by detecting person, bicycle, car, motorcycle, bus, and truck
- **Single-class backend** (`bgsub`) produces unclassified detections (CPU-only fallback)
- All count events store `detection_backend` field to track which detector was used
- Class-based statistics available via `/api/stats/by-class` for advocacy reports showing car vs bike vs pedestrian volumes

### YOLO Detection (GPU/CPU)

```yaml
detection:
  backend: "yolo"
  yolo:
    model: "yolov8s.pt"      # Model file (auto-downloads)
    conf_threshold: 0.25     # Baseline threshold (run YOLO permissively)
    classes: [0, 1, 2, 3, 5, 7]  # COCO class IDs to detect
    
    # Class-specific confidence thresholds (applied post-detection)
    # Different thresholds for different object types improve detection:
    # - Lower for small/hard objects (pedestrians, bicycles)
    # - Higher for large/easy objects (cars, buses)
    class_thresholds:
      0: 0.20   # person - LOW (critical for safety, often missed)
      1: 0.25   # bicycle - LOW (important for modal split)
      2: 0.40   # car - HIGH (large, easy to detect)
      3: 0.30   # motorcycle - MEDIUM
      5: 0.45   # bus - HIGH (very large)
      7: 0.45   # truck - HIGH (very large)
```

**Detected classes**: person, bicycle, car, motorcycle, bus, truck (COCO IDs 0, 1, 2, 3, 5, 7)

**Class-Specific Thresholds**: YOLO uses a two-stage filtering approach:
1. Run YOLO with low baseline threshold (0.25) to capture all potential detections
2. Apply class-specific thresholds post-detection to tune sensitivity per class

This dramatically improves pedestrian and bicycle detection (+300-400%) without increasing false positives for cars.

**Requirements**: `pip install ultralytics` (GPU auto-detected via PyTorch CUDA)

### Background Subtraction (Default)

```yaml
detection:
  backend: "bgsub"
  min_contour_area: 1000
  detect_shadows: true
```

No external dependencies. Works on any hardware but doesn't classify objects.

## Configuration Architecture

The system uses a **3-layer configuration architecture** to separate universal defaults, deployment settings, and site-specific calibration:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 1: config/default.yaml (checked in)                  ‚îÇ
‚îÇ   Universal defaults, works everywhere                      ‚îÇ
‚îÇ   Example: detection thresholds, counting parameters        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì (overridden by)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 2: config/config.yaml (gitignored)                   ‚îÇ
‚îÇ   Deployment-specific operational settings                  ‚îÇ
‚îÇ   Example: camera backend, resolution, fps                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì (overridden by)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Layer 3: data/calibration/site.yaml (gitignored)           ‚îÇ
‚îÇ   Site-specific measured geometry                           ‚îÇ
‚îÇ   Example: gate line coordinates, camera orientation        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Why 3 Layers?

**Separation of Concerns:**
- **Configuration** (Layer 1-2): Settings you change operationally (resolution, thresholds)
- **Calibration** (Layer 3): Geometry you measure once and rarely change (gate coordinates)

**Benefits:**
- ‚úÖ Clean separation between config and calibration
- ‚úÖ Calibration managed separately via `/api/calibration` endpoint
- ‚úÖ Backwards compatible (site.yaml is optional)
- ‚úÖ Multi-site deployments can share defaults, customize per-site

### Configuration Files

**`config/default.yaml`** (checked in):
- Universal defaults that work everywhere
- Detection thresholds, counting parameters, API settings
- Base configuration shipped with the software

**`config/config.yaml`** (gitignored, optional):
- Deployment-specific operational settings
- Camera backend, resolution, detection backend
- Overrides defaults for this specific deployment

**`data/calibration/site.yaml`** (gitignored, optional):
- Site-specific measured geometry
- Gate line coordinates, direction labels
- Camera orientation (rotate, flip)
- Overrides config for calibration-specific fields

### Creating Calibration File

**Option 1: Use the web UI**
1. Access `http://localhost:5000`
2. Configure gate lines via `/api/calibration` endpoint
3. File is automatically created at `data/calibration/site.yaml`

**Option 2: Create manually**
```bash
cp data/calibration/site.yaml.example data/calibration/site.yaml
# Edit coordinates to match your camera view
```

**Option 3: Migrate from existing config.yaml**
```bash
python tools/migrate_config_to_calibration.py
# Extracts calibration data from config.yaml to site.yaml
# Safe: creates backups before modifying files
```

### API Endpoints

| Endpoint | Purpose | File Modified |
|----------|---------|---------------|
| `GET /api/calibration` | Fetch calibration (gate lines, orientation) | - |
| `POST /api/calibration` | Save calibration | `data/calibration/site.yaml` |
| `GET /api/config` | Fetch full effective config | - |

The effective configuration is the deep merge of all 3 layers:

```python
effective_config = default ‚Üê config ‚Üê calibration
```

## Raspberry Pi Deployment

### Automated Setup

```bash
ssh pi@traffic-pi.local
git clone https://github.com/your-username/traffic-monitor.git
cd traffic-monitor
chmod +x tools/deploy_pi.sh
sudo ./tools/deploy_pi.sh
```

### Manual Setup

```bash
# Install system packages
sudo apt update
sudo apt install -y git python3 python3-venv python3-pip \
  python3-opencv python3-picamera2 rpicam-apps nodejs npm

# Create venv (include system packages for picamera2)
python3 -m venv --system-site-packages .venv
source .venv/bin/activate

# Install Python deps (skip opencv-python on Pi)
grep -v '^opencv-python' requirements.txt > /tmp/req.txt
pip install -r /tmp/req.txt

# Build frontend
cd frontend && npm install && npm run build && cd ..

# Create systemd service
sudo nano /etc/systemd/system/traffic-monitor.service
```

Systemd service file:
```ini
[Unit]
Description=Traffic Monitor
After=network.target

[Service]
Type=simple
User=pi
WorkingDirectory=/home/pi/traffic-monitor
Environment="PATH=/home/pi/traffic-monitor/.venv/bin:/usr/bin"
ExecStart=/home/pi/traffic-monitor/.venv/bin/python src/main.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

Enable and start:
```bash
sudo systemctl daemon-reload
sudo systemctl enable traffic-monitor
sudo systemctl start traffic-monitor
```

## API Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /api/status` | Compact status for dashboard polling |
| `GET /api/health` | System health info |
| `GET /api/stats/summary` | Count statistics |
| `GET /api/stats/by-class` | Modal split statistics (by object class) |
| `GET /api/stats/live` | Real-time stats |
| `GET /api/config` | Current configuration |
| `POST /api/config` | Save config overrides |
| `GET /api/calibration` | Calibration settings |
| `POST /api/calibration` | Save calibration |
| `GET /api/camera/live.mjpg` | MJPEG video stream |
| `GET /api/camera/snapshot.jpg` | Single frame snapshot |

### Modal Split Statistics

The `/api/stats/by-class` endpoint provides object class breakdowns for modal split analysis:

```bash
curl "http://localhost:5000/api/stats/by-class?start_ts=1704067200&end_ts=1704153600"
```

Returns:
```json
{
  "total": 150,
  "by_class": {
    "car": 85,
    "bicycle": 12,
    "person": 8,
    "motorcycle": 5,
    "bus": 3,
    "truck": 4,
    "unclassified": 33
  },
  "by_class_and_direction": {
    "car": {"A_TO_B": 45, "B_TO_A": 40},
    "bicycle": {"A_TO_B": 8, "B_TO_A": 4}
  },
  "unclassified": 33,
  "time_range": {"start": 1704067200, "end": 1704153600}
}
```

**Use Cases:**
- **Advocacy**: "Show that 85% of traffic is through-traffic, not local residents"
- **Modal split**: "Demonstrate need for bike lanes with actual cyclist counts"
- **Time-of-day**: "Identify peak hours for speed enforcement requests"
- **Before/after**: "Measure effectiveness of traffic calming interventions"

**Note:** Multi-class detection requires `detection.backend='yolo'` or `'hailo'`. Background subtraction (`bgsub`) is CPU-only but produces unclassified detections.

## Cloud Sync (Optional)

To sync data to Google Cloud BigQuery:

1. Create a GCP project
2. Enable BigQuery API
3. Create a service account with `BigQuery Data Editor` role
4. Download key to `secrets/gcp-credentials.json`
5. Configure `config/cloud_config.yaml`

## Development

```bash
# Run tests
pytest tests/ -v

# Build frontend in dev mode
cd frontend && npm run dev

# Run backend
python src/main.py --display
```

## Current Implementation Status

### ‚úÖ Milestone 0 ‚Äî Deployment Readiness (COMPLETE)
- Runs headless without intervention
- Auto-recovers from camera failures
- Documented setup steps
- Systemd service for Raspberry Pi
- Single-instance enforcement via PID file

### ‚úÖ Milestone 1 ‚Äî Core Counting (COMPLETE)
- Background subtraction detection
- IoU-based tracking with double-count prevention
- Gate counting (two-line, bi-directional) + Line counting (fallback)
- SQLite storage with `count_events` table (schema v3)
- Web interface (FastAPI + React)

### ‚úÖ Milestone 2 ‚Äî AI Detection (COMPLETE)
- YOLO backend via Ultralytics (GPU/CPU)
- Multi-class detection (person, bicycle, car, motorcycle, bus, truck)
- Configurable detection backend (`bgsub`, `yolo`, `hailo`)
- Hardware-aware logging (shows GPU name or CPU fallback)
- Full pipeline integration (detection ‚Üí tracking ‚Üí counting ‚Üí storage)
- **Schema v3** with class metadata (class_id, class_name, confidence, backend, platform, process_pid)
- **Class-specific confidence thresholds** (improves pedestrian/bicycle detection by 300-400%)
- Migration tools for config and BigQuery schema

### üîÑ Milestone 4 ‚Äî Modal Split Analytics (BACKEND COMPLETE, FRONTEND IN PROGRESS)
- ‚úÖ Multi-class detection (via YOLO backend)
- ‚úÖ Class metadata stored in database (schema v3)
- ‚úÖ Class-based statistics API (`/api/stats/by-class`)
- ‚úÖ Trends page in frontend (time-series visualization)
- ‚è≥ Enhanced Dashboard modal split display
- ‚è≥ Class-specific time-of-day patterns
- ‚è≥ Modal split reports (vehicles vs pedestrians vs cyclists)
- ‚è≥ Validation procedure for class accuracy

### ‚è≥ Milestone 3 ‚Äî Speed Measurement (NOT STARTED)
- Camera calibration procedure
- Ground-plane speed estimation
- Speed distribution statistics
- Validation against reference

### ‚è≥ Milestone 5 ‚Äî Heatmaps (NOT STARTED)
- Trajectory aggregation
- Time-bucketed occupancy grids
- Bird's-eye view transformation

### ‚è≥ Milestone 6 ‚Äî Reliability & Monitoring (PARTIAL)
- ‚úÖ Health status endpoint with system metrics
- ‚úÖ Disk usage and temperature monitoring
- ‚è≥ Alerting for camera offline
- ‚è≥ Uptime tracking dashboard
- ‚è≥ Cost controls for cloud

### ‚è≥ Milestone 7 ‚Äî Advocacy Packaging (NOT STARTED)
- Chart generation
- One-page summary template
- Before/after comparison tools
- CSV/PDF exports

## Data Collection

The system collects the following data:

**Per Count Event (stored in SQLite, schema v3):**
- Timestamp (epoch milliseconds)
- Track ID (transient, resets on restart)
- Direction (A_TO_B / B_TO_A)
- Object class (person, bicycle, car, motorcycle, bus, truck, or NULL)
- Detection confidence score
- Gate crossing frames
- Track age and displacement
- Detection backend used (bgsub, yolo, hailo)
- Platform info (OS, Python version)
- Process PID (for debugging)

**Video Data:**
- Live MJPEG stream available via web interface (not stored)
- Optional recording to disk if `--record` flag is used
- No long-term video retention by default (disk space constraints)

**Cloud Sync (optional):**
- Count events synced to BigQuery for long-term analysis
- No video data uploaded to cloud
- Configurable sync interval and retention

## Performance

Tested configurations:

| Hardware | Backend | FPS | Use Case |
|----------|---------|-----|----------|
| Desktop (RTX 3060) | YOLO (GPU) | 30 | Development, multi-class detection |
| Desktop (CPU) | YOLO (CPU) | 10-15 | Testing without GPU |
| Raspberry Pi 5 | Background Sub | 20-25 | Edge deployment, single-class |
| Raspberry Pi 5 + AI HAT+ | Hailo (planned) | 20-30 | Edge deployment with classification |

## Documentation

Comprehensive project documentation is available in the `docs/` directory:

- **[PLAN.md](docs/PLAN.md)** - Living roadmap, architecture, milestones, and configuration guide
- **[ARCHITECT_CONSTITUTION.md](docs/architect_constitution.md)** - Non-negotiable design principles and governance
- **[DATA_MODEL_REVIEW.md](docs/DATA_MODEL_REVIEW.md)** - Data model analysis and schema v3 design
- **[SCHEMA_V3_MIGRATION.md](docs/SCHEMA_V3_MIGRATION.md)** - Migration guide for schema v3
- **[IMPLEMENTATION_SUMMARY.md](docs/IMPLEMENTATION_SUMMARY.md)** - Schema v3 implementation details
- **[RESTART_INSTRUCTIONS.md](RESTART_INSTRUCTIONS.md)** - Quick reference for developers

### Governance

This project follows strict architectural governance to ensure data quality, privacy, and reliability:

- **Evidence-grade data**: Every measurement must be reproducible and documented
- **Edge-first**: System must work without internet access
- **Defense in depth**: Multiple layers prevent double-counting
- **Architectural boundaries**: Clear layer separation (observation ‚Üí detection ‚Üí tracking ‚Üí counting ‚Üí storage ‚Üí web)
- **Small, reviewable changes**: Prefer incremental improvements over sweeping rewrites

See [ARCHITECT_CONSTITUTION.md](docs/architect_constitution.md) for complete principles.

## Contributing

Contributions welcome! Please:

1. Read [ARCHITECT_CONSTITUTION.md](docs/architect_constitution.md) and [PLAN.md](docs/PLAN.md)
2. Make small, testable, incremental changes
3. Add tests for new functionality
4. Update documentation as needed
5. Open an issue or PR

## License

MIT License - see [LICENSE](LICENSE)
