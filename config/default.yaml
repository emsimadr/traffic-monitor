# Default configuration (checked into source control).
#
# Copy this file to `config/config.yaml` and override only what you need for your
# local deployment (camera URL, counting line, cloud settings, etc.).

# Camera settings
camera:
  # backend selection:
  # - "opencv": supports USB webcams (device_id: 0) AND RTSP IP cameras
  # - "picamera2": supports Raspberry Pi CSI cameras (ignores device_id)
  backend: "opencv"
  # device_id: 0 for USB webcam, or omit for RTSP (loaded from secrets_file)
  device_id: 0
  # For RTSP cameras: put rtsp_url + credentials in secrets/camera_secrets.yaml
  # Example secrets file:
  #   rtsp_url: "rtsp://192.168.1.100/live0"
  #   username: "user"
  #   password: "pass"
  secrets_file: "secrets/camera_secrets.yaml"
  resolution: [1280, 720]        # Camera resolution [width, height]
  fps: 30                        # Frames per second
  # Optional image calibration (applied after capture, before detection)
  # swap_rb: true can fix "wrong colors" when a pipeline delivers RGB but code expects BGR.
  # rotate: 0|90|180|270
  # flip_horizontal / flip_vertical: booleans
  swap_rb: false
  rotate: 0
  flip_horizontal: false
  flip_vertical: false

# Detection settings
detection:
  # backend options:
  #   - "bgsub": Background subtraction (default, no dependencies, works everywhere)
  #   - "yolo": YOLO via Ultralytics (requires: pip install ultralytics; uses GPU if available)
  #   - "hailo": YOLO on Hailo AI HAT+ (Pi 5 only; requires: apt install hailo-all)
  backend: "bgsub"
  min_contour_area: 1000         # Minimum contour area for vehicle detection (bgsub only)
  detect_shadows: true           # Whether to detect shadows in background subtraction

  # YOLO settings (used when detection.backend is "yolo" or "hailo")
  yolo:
    # Model path: Ultralytics model name or path to .pt file
    # Recommended: "yolov8s.pt" (good accuracy/speed balance)
    # Alternatives: "yolov8n.pt" (faster), "yolov8m.pt" (more accurate)
    model: "yolov8s.pt"
    
    # Baseline confidence threshold for YOLO inference
    # Set low (0.25) to capture all potential detections; class-specific thresholds applied after
    conf_threshold: 0.25
    iou_threshold: 0.45          # NMS IoU threshold
    
    # Class filtering: COCO class IDs for neighborhood traffic
    # 0=person, 1=bicycle, 2=car, 3=motorcycle, 5=bus, 7=truck
    # Detect all relevant classes; counting can filter further
    classes: [0, 1, 2, 3, 5, 7]
    
    # Human-readable names for detected classes
    class_name_overrides:
      0: "person"
      1: "bicycle"
      2: "car"
      3: "motorcycle"
      5: "bus"
      7: "truck"
    
    # Class-specific confidence thresholds (applied post-detection)
    # Different object types require different sensitivity:
    # - Lower thresholds for small/hard objects (pedestrians, bicycles)
    # - Higher thresholds for large/easy objects (cars, buses)
    # This significantly improves pedestrian/bicycle detection without increasing false positives
    class_thresholds:
      0: 0.20   # person - LOW (critical for safety, small in frame)
      1: 0.25   # bicycle - LOW (important for modal split)
      2: 0.40   # car - HIGH (large, easy to detect, reduce false positives)
      3: 0.30   # motorcycle - MEDIUM
      5: 0.45   # bus - HIGH (very large, easy to detect)
      7: 0.45   # truck - HIGH (very large, easy to detect)

  # Hailo settings (used only when detection.backend == "hailo")
  # Requires Raspberry Pi 5 with AI HAT+ and hailo-all package installed
  hailo:
    # Path to compiled HEF model (Hailo Executable Format)
    # To compile: Use Hailo Dataflow Compiler (see docs/DEPLOYMENT.md)
    # Download pre-compiled: [URL to be added]
    hef_path: "data/artifacts/yolov8s.hef"
    
    # Model input dimensions [width, height]
    # Must match HEF compilation settings
    # 640x640 recommended for balanced accuracy/speed
    input_size: [640, 640]
    
    # Baseline confidence threshold for inference
    # Set low to capture all detections; class-specific thresholds applied after
    conf_threshold: 0.25
    iou_threshold: 0.45
    
    # Class filtering: COCO class IDs for neighborhood traffic
    # Same as YOLO backend for consistency
    classes: [0, 1, 2, 3, 5, 7]
    
    # Human-readable names for detected classes
    class_name_overrides:
      0: "person"
      1: "bicycle"
      2: "car"
      3: "motorcycle"
      5: "bus"
      7: "truck"
    
    # Class-specific confidence thresholds (applied post-detection)
    # Lower thresholds for small/hard objects, higher for large/easy objects
    class_thresholds:
      0: 0.20   # person - LOW (critical for safety, small in frame)
      1: 0.25   # bicycle - LOW (important for modal split)
      2: 0.40   # car - HIGH (large, easy to detect)
      3: 0.30   # motorcycle - MEDIUM
      5: 0.45   # bus - HIGH (very large)
      7: 0.45   # truck - HIGH (very large)

# Counting strategy
counting:
  # mode: "gate" (two-line gate, default) or "line" (single-line fallback)
  # Gate counting is the standard for bi-directional streets.
  # - gate: counts when track crosses line_a then line_b (A_TO_B) or vice versa (B_TO_A)
  # - line: fallback for cases where a gate is not feasible
  mode: "gate"
  
  # Line definitions (as ratios [0-1] of frame dimensions)
  # Both lines are used for gate mode; only line_a for line mode
  line_a: [[0.2, 1.0], [0.0, 0.0]]   # Line A (ratios)
  line_b: [[0.8, 1.0], [1.0, 0.0]]   # Line B (ratios)
  
  # Direction labels (how directions appear in logs/UI)
  # Both modes use A_TO_B/B_TO_A direction codes for DB/API consistency
  direction_labels:
    a_to_b: "northbound"  # Crossed A then B (or positive side in line mode)
    b_to_a: "southbound"  # Crossed B then A (or negative side in line mode)
  
  # Counting constraints (apply to both modes)
  min_age_frames: 3           # Min track age before counting
  min_displacement_px: 15.0   # Min movement distance (pixels) for valid count
  
  # Gate-specific settings (only used when mode: "gate")
  max_gap_frames: 30          # Max frames between line A and line B crossings

# Storage settings
storage:
  local_database_path: "data/database.sqlite"  # Path to local SQLite database
  retention_days: 30                          # How long to keep data locally
  use_cloud_storage: true                     # Whether to use cloud storage
  sync_enabled: true                          # Whether to sync data to cloud

# Tracking settings (vehicle tracker configuration)
tracking:
  max_frames_since_seen: 10     # Frames to keep a track alive without detection
  min_trajectory_length: 3      # Points needed before deciding direction
  iou_threshold: 0.3            # IoU match threshold between detections

# System settings
log_path: "logs/traffic_monitor.log"  # Path to log file
log_level: "INFO"                     # Logging level (DEBUG, INFO, WARNING, ERROR)

# Pipeline settings (experimental)
pipeline:
  # Use the new pipeline engine (observation layer).
  # Set to true to enable the new modular pipeline architecture.
  # Default: false (uses legacy main loop for safety).
  use_new_engine: false


